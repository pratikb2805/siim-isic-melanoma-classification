{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"TPU\"\n",
    "\n",
    "CFG = dict(\n",
    "    net_count         =   2,  #No. of models to combine\n",
    "    \n",
    "    batch_size        =  16,\n",
    "    \n",
    "    read_size         = 512, \n",
    "    crop_size         = 500, \n",
    "    net_size          = 512, \n",
    "    \n",
    "    LR_START          =   0.000005,\n",
    "    LR_MAX            =   0.000020,\n",
    "    LR_MIN            =   0.000001,\n",
    "    LR_RAMPUP_EPOCHS  =   5,\n",
    "    LR_SUSTAIN_EPOCHS =   0,\n",
    "    LR_EXP_DECAY      =   0.8,\n",
    "    epochs            =  15,\n",
    "    \n",
    "    rot               = 180.0,\n",
    "    shr               =   2.0,\n",
    "    hzoom             =   8.0,\n",
    "    wzoom             =   8.0,\n",
    "    hshift            =   8.0,\n",
    "    wshift            =   8.0,\n",
    "\n",
    "    optimizer         = 'adam',\n",
    "    label_smooth_fac  =   0.05,\n",
    "    \n",
    "    tta_steps         =  25    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, re, math, time\n",
    "random.seed(a=42)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "import PIL\n",
    "\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEPATH = \"../input/siim-isic-melanoma-classification\"\n",
    "df_train = pd.read_csv(os.path.join(BASEPATH, 'train.csv'))\n",
    "df_test  = pd.read_csv(os.path.join(BASEPATH, 'test.csv'))\n",
    "df_sub   = pd.read_csv(os.path.join(BASEPATH, 'sample_submission.csv'))\n",
    "\n",
    "GCS_PATH    = KaggleDatasets().get_gcs_path('melanoma-512x512')\n",
    "GCS_PATH2    = KaggleDatasets().get_gcs_path('isic2019-512x512')\n",
    "files_train = tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')\n",
    "files_train += tf.io.gfile.glob(GCS_PATH2 + '/train*.tfrec')\n",
    "np.random.shuffle(files_train)\n",
    "files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/test*.tfrec')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to TPU...\n",
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "initializing  TPU ...\n",
      "TPU initialized\n",
      "REPLICAS: 8\n"
     ]
    }
   ],
   "source": [
    "if DEVICE == \"TPU\":\n",
    "    print(\"connecting to TPU...\")\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        print(\"Could not connect to TPU\")\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        try:\n",
    "            print(\"initializing  TPU ...\")\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "            print(\"TPU initialized\")\n",
    "        except _:\n",
    "            print(\"failed to initialize TPU\")\n",
    "    else:\n",
    "        DEVICE = \"GPU\"\n",
    "\n",
    "if DEVICE != \"TPU\":\n",
    "    print(\"Using default strategy for CPU and single GPU\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "if DEVICE == \"GPU\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    \n",
    "\n",
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear    = math.pi * shear    / 180.\n",
    "\n",
    "    def get_3x3_mat(lst):\n",
    "        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1   = tf.math.cos(rotation)\n",
    "    s1   = tf.math.sin(rotation)\n",
    "    one  = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    \n",
    "    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n",
    "                                   -s1,  c1,   zero, \n",
    "                                   zero, zero, one])    \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)    \n",
    "    \n",
    "    shear_matrix = get_3x3_mat([one,  s2,   zero, \n",
    "                                zero, c2,   zero, \n",
    "                                zero, zero, one])        \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n",
    "                               zero,            one/width_zoom, zero, \n",
    "                               zero,            zero,           one])    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), \n",
    "                 K.dot(zoom_matrix,     shift_matrix))\n",
    "\n",
    "\n",
    "def transform(image, cfg):    \n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    DIM = cfg[\"read_size\"]\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rot = cfg['rot'] * tf.random.normal([1], dtype='float32')\n",
    "    shr = cfg['shr'] * tf.random.normal([1], dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['hzoom']\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['wzoom']\n",
    "    h_shift = cfg['hshift'] * tf.random.normal([1], dtype='float32') \n",
    "    w_shift = cfg['wshift'] * tf.random.normal([1], dtype='float32') \n",
    "\n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n",
    "    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n",
    "    z   = tf.ones([DIM*DIM], dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n",
    "    idx2 = K.cast(idx2, dtype='int32')\n",
    "    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n",
    "    d    = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM, DIM,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n",
    "    }           \n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['target']\n",
    "\n",
    "\n",
    "def read_unlabeled_tfrecord(example, return_image_name):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['image_name'] if return_image_name else 0\n",
    "\n",
    " \n",
    "def prepare_image(img, cfg=None, augment=True):    \n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [cfg['read_size'], cfg['read_size']])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    if augment:\n",
    "        img = transform(img, cfg)\n",
    "        img = tf.image.random_crop(img, [cfg['crop_size'], cfg['crop_size'], 3])\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        # img = tf.image.random_hue(img, 0.01)\n",
    "        img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "\n",
    "    else:\n",
    "        img = tf.image.central_crop(img, cfg['crop_size'] / cfg['read_size'])\n",
    "                                   \n",
    "    img = tf.image.resize(img, [cfg['net_size'], cfg['net_size']])\n",
    "    img = tf.reshape(img, [cfg['net_size'], cfg['net_size'], 3])\n",
    "    return img\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n",
    "         for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(files, cfg, augment = False, shuffle = False, repeat = False, \n",
    "                labeled=True, return_image_names=True):\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    ds = ds.cache()\n",
    "    \n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    \n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(1024*8)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "        \n",
    "    if labeled: \n",
    "        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), \n",
    "                    num_parallel_calls=AUTO)      \n",
    "    \n",
    "    ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, cfg=cfg), \n",
    "                                               imgname_or_label), \n",
    "                num_parallel_calls=AUTO)\n",
    "    \n",
    "    ds = ds.batch(cfg['batch_size'] * REPLICAS)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_callback(cfg):\n",
    "    lr_start   = cfg['LR_START']\n",
    "    lr_max     = cfg['LR_MAX'] * strategy.num_replicas_in_sync\n",
    "    lr_min     = cfg['LR_MIN']\n",
    "    lr_ramp_ep = cfg['LR_RAMPUP_EPOCHS']\n",
    "    lr_sus_ep  = cfg['LR_SUSTAIN_EPOCHS']\n",
    "    lr_decay   = cfg['LR_EXP_DECAY']\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "            \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "            \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(cfg):\n",
    "    model_input = tf.keras.Input(shape=(cfg['net_size'], cfg['net_size'], 3), name='imgIn')\n",
    "\n",
    "    dummy = tf.keras.layers.Lambda(lambda x:x)(model_input)\n",
    "    \n",
    "    outputs = []    \n",
    "    for i in range(cfg['net_count']):\n",
    "        constructor = getattr(efn, f'EfficientNetB{i}')\n",
    "        \n",
    "        x = constructor(include_top=False, weights='noisy-student', \n",
    "                        input_shape=(cfg['net_size'], cfg['net_size'], 3), \n",
    "                        pooling='avg')(dummy)\n",
    "        \n",
    "        x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "        outputs.append(x)\n",
    "        \n",
    "    model = tf.keras.Model(model_input, outputs, name='aNetwork')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_new_model(cfg):    \n",
    "    with strategy.scope():\n",
    "        model = get_model(cfg)\n",
    "     \n",
    "        losses = [tf.keras.losses.BinaryCrossentropy(label_smoothing = cfg['label_smooth_fac'])\n",
    "                  for i in range(cfg['net_count'])]\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer = cfg['optimizer'],\n",
    "            loss      = losses,\n",
    "            metrics   = [tf.keras.metrics.AUC(name='auc')])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_noisy-student_notop.h5\n",
      "16703488/16696600 [==============================] - 0s 0us/step\n",
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b1_noisy-student_notop.h5\n",
      "27017216/27010080 [==============================] - 0s 0us/step\n",
      "Model: \"aNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "imgIn (InputLayer)              [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 512, 512, 3)  0           imgIn[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b0 (Model)         (None, 1280)         4049564     lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b1 (Model)         (None, 1280)         6575232     lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1281        efficientnet-b0[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1281        efficientnet-b1[1][0]            \n",
      "==================================================================================================\n",
      "Total params: 10,627,358\n",
      "Trainable params: 10,523,294\n",
      "Non-trainable params: 104,064\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "454/453 [==============================] - 227s 501ms/step - dense_auc: 0.6963 - dense_loss: 0.4480 - dense_1_auc: 0.6992 - loss: 0.8560 - dense_1_loss: 0.4079 - lr: 5.0000e-06\n",
      "Epoch 2/15\n",
      "454/453 [==============================] - 228s 501ms/step - dense_auc: 0.8590 - dense_loss: 0.2841 - dense_1_auc: 0.8592 - loss: 0.5680 - dense_1_loss: 0.2839 - lr: 3.6000e-05\n",
      "Epoch 3/15\n",
      "454/453 [==============================] - 229s 505ms/step - dense_auc: 0.8947 - dense_loss: 0.2641 - dense_1_auc: 0.8958 - loss: 0.5274 - dense_1_loss: 0.2633 - lr: 6.7000e-05\n",
      "Epoch 4/15\n",
      "454/453 [==============================] - 228s 503ms/step - dense_auc: 0.9061 - dense_loss: 0.2560 - dense_1_auc: 0.9056 - loss: 0.5125 - dense_1_loss: 0.2565 - lr: 9.8000e-05\n",
      "Epoch 5/15\n",
      "454/453 [==============================] - 229s 505ms/step - dense_auc: 0.9189 - dense_loss: 0.2470 - dense_1_auc: 0.9162 - loss: 0.4951 - dense_1_loss: 0.2482 - lr: 1.2900e-04\n",
      "Epoch 6/15\n",
      "454/453 [==============================] - 229s 505ms/step - dense_auc: 0.9256 - dense_loss: 0.2419 - dense_1_auc: 0.9232 - loss: 0.4854 - dense_1_loss: 0.2435 - lr: 1.6000e-04\n",
      "Epoch 7/15\n",
      "454/453 [==============================] - 229s 504ms/step - dense_auc: 0.9375 - dense_loss: 0.2327 - dense_1_auc: 0.9374 - loss: 0.4656 - dense_1_loss: 0.2329 - lr: 1.2820e-04\n",
      "Epoch 8/15\n",
      "454/453 [==============================] - 228s 503ms/step - dense_auc: 0.9459 - dense_loss: 0.2243 - dense_1_auc: 0.9448 - loss: 0.4497 - dense_1_loss: 0.2254 - lr: 1.0276e-04\n",
      "Epoch 9/15\n",
      "454/453 [==============================] - 228s 503ms/step - dense_auc: 0.9487 - dense_loss: 0.2207 - dense_1_auc: 0.9486 - loss: 0.4414 - dense_1_loss: 0.2207 - lr: 8.2408e-05\n",
      "Epoch 10/15\n",
      "454/453 [==============================] - 228s 503ms/step - dense_auc: 0.9567 - dense_loss: 0.2139 - dense_1_auc: 0.9549 - loss: 0.4286 - dense_1_loss: 0.2147 - lr: 6.6126e-05\n",
      "Epoch 11/15\n",
      "454/453 [==============================] - 228s 503ms/step - dense_auc: 0.9586 - dense_loss: 0.2102 - dense_1_auc: 0.9573 - loss: 0.4209 - dense_1_loss: 0.2107 - lr: 5.3101e-05\n",
      "Epoch 12/15\n",
      "454/453 [==============================] - 229s 505ms/step - dense_auc: 0.9613 - dense_loss: 0.2070 - dense_1_auc: 0.9594 - loss: 0.4151 - dense_1_loss: 0.2081 - lr: 4.2681e-05\n",
      "Epoch 13/15\n",
      "454/453 [==============================] - 230s 507ms/step - dense_auc: 0.9651 - dense_loss: 0.2039 - dense_1_auc: 0.9631 - loss: 0.4085 - dense_1_loss: 0.2045 - lr: 3.4345e-05\n",
      "Epoch 14/15\n",
      "454/453 [==============================] - 229s 504ms/step - dense_auc: 0.9662 - dense_loss: 0.2016 - dense_1_auc: 0.9646 - loss: 0.4036 - dense_1_loss: 0.2020 - lr: 2.7676e-05\n",
      "Epoch 15/15\n",
      "454/453 [==============================] - 230s 506ms/step - dense_auc: 0.9680 - dense_loss: 0.1994 - dense_1_auc: 0.9662 - loss: 0.3999 - dense_1_loss: 0.2005 - lr: 2.2341e-05\n"
     ]
    }
   ],
   "source": [
    "ds_train     = get_dataset(files_train, CFG, augment=True, shuffle=True, repeat=True)\n",
    "ds_train     = ds_train.map(lambda img, label: (img, tuple([label] * CFG['net_count'])))\n",
    "\n",
    "steps_train  = count_data_items(files_train) / (CFG['batch_size'] * REPLICAS)\n",
    "\n",
    "model        = compile_new_model(CFG)\n",
    "history      = model.fit(ds_train, \n",
    "                         verbose          = 1,\n",
    "                         steps_per_epoch  = steps_train, \n",
    "                         epochs           = CFG['epochs'],\n",
    "                         callbacks        = [get_lr_callback(CFG)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the test set using augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/536 [==============================] - 346s 645ms/step\n"
     ]
    }
   ],
   "source": [
    "CFG['batch_size'] = 64\n",
    "\n",
    "cnt_test   = count_data_items(files_test)\n",
    "steps      = cnt_test / (CFG['batch_size'] * REPLICAS) * CFG['tta_steps']\n",
    "ds_testAug = get_dataset(files_test, CFG, augment=True, repeat=True, \n",
    "                         labeled=False, return_image_names=False)\n",
    "\n",
    "probs = model.predict(ds_testAug, verbose=1, steps=steps)\n",
    "\n",
    "probs = np.stack(probs)\n",
    "probs = probs[:,:cnt_test * CFG['tta_steps']]\n",
    "probs = np.stack(np.split(probs, CFG['tta_steps'], axis=1), axis=1)\n",
    "probs = np.mean(probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort predictions to have the same order as the submission\n",
    "The submission ist sorted by image_name, but the dataset yielded a different order.\n",
    "Traverse the test dataset once again and capture the image_names. Then join this list of image_names with the predictions and sort by image_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_dataset(files_test, CFG, augment=False, repeat=False, \n",
    "                 labeled=False, return_image_names=True)\n",
    "\n",
    "image_names = np.array([img_name.numpy().decode(\"utf-8\") \n",
    "                        for img, img_name in iter(ds.unbatch())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a submission file for each submodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(CFG[\"net_count\"]):\n",
    "    submission = pd.DataFrame(dict(\n",
    "        image_name = image_names,\n",
    "        target     = probs[i,:,0]))\n",
    "\n",
    "    submission = submission.sort_values('image_name') \n",
    "    submission.to_csv(f'submission_model_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Write a submission file using the mean of all submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(dict(\n",
    "    image_name = image_names,\n",
    "    target     = np.mean(probs[:,:,0], axis=0)))\n",
    "\n",
    "submission = submission.sort_values('image_name') \n",
    "submission.to_csv('submission_models_blended.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q efficientnet_pytorch > /dev/null\n",
    "!pip install -q torchcontrib\n",
    "!!pip install --no-deps timm > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import albumentations as A\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.nn import functional as F\n",
    "from glob import glob\n",
    "import sklearn\n",
    "from torch import nn\n",
    "import warnings\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import types\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from catalyst.data.sampler import BalanceClassSampler\n",
    "import os\n",
    "import timm\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import time\n",
    "import random\n",
    "import sklearn\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from torchvision import transforms, utils\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/melanoma-merged-external-data-512x512-jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Microscope:\n",
    "    def __init__(self, p: float = 0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            circle = cv2.circle((np.ones(img.shape) * 255).astype(np.uint8),\n",
    "                        (img.shape[0]//2, img.shape[1]//2),\n",
    "                        random.randint(img.shape[0]//2 - 3, img.shape[0]//2 + 15),\n",
    "                        (0, 0, 0),\n",
    "                        -1)\n",
    "\n",
    "            mask = circle - 255\n",
    "            img = np.multiply(img, mask)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(p={self.p})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "            A.RandomSizedCrop(min_max_height=(400, 400), height=768, width=768, p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Resize(height=512, width=512, p=1),\n",
    "            A.Cutout(num_holes=8, max_h_size=96, max_w_size=96, fill_value=0, p=0.5),\n",
    "            ToTensorV2(p=1.0),                  \n",
    "        ], p=1.0)\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "            A.Resize(height=768, width=768, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class RocAucMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.y_true = np.array([0,1])\n",
    "        self.y_pred = np.array([0.5,0.5])\n",
    "        self.score = 0\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n",
    "        # y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n",
    "        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n",
    "        self.y_true = np.hstack((self.y_true, y_true))\n",
    "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
    "        self.score = sklearn.metrics.roc_auc_score(self.y_true, self.y_pred)\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        return self.score\n",
    "\n",
    "    \n",
    "class APScoreMeter(RocAucMeter):\n",
    "    def __init__(self):\n",
    "        super(APScoreMeter, self).__init__()\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n",
    "        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n",
    "        self.y_true = np.hstack((self.y_true, y_true))\n",
    "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
    "        self.score = sklearn.metrics.average_precision_score(self.y_true, self.y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets)\n",
    "\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing = 0.1):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        if self.training:\n",
    "            x = x.float()\n",
    "            target = target.float()\n",
    "            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n",
    "\n",
    "            nll_loss = -logprobs * target\n",
    "            nll_loss = nll_loss.sum(-1)\n",
    "    \n",
    "            smooth_loss = -logprobs.mean(dim=-1)\n",
    "\n",
    "            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return torch.nn.functional.cross_entropy(x, target)\n",
    "        \n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "        \n",
    "        return Dice_BCE        \n",
    "    \n",
    "class FocalDiceLoss(nn.Module):\n",
    "    def __init__(self,alpha=1, gamma=2, logits=True, reduce=False,weight=None, size_average=True):\n",
    "        super(FocalDiceLoss,self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "   \n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets)\n",
    "\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "        \n",
    "        \n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)+dice_loss\n",
    "        else:\n",
    "            return F_loss+ dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    net = timm.create_model('efficientnet_b3',pretrained=True)\n",
    "    net.classifier = nn.Linear(in_features=net.classifier.in_features, out_features=1000, bias=True)\n",
    "#     print(net.classifier.in_features)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "class MetaNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaNet, self).__init__()\n",
    "        self.meta_before = FeedForwardNN()\n",
    "        self.mainnet = get_net()\n",
    "        self.metaaux = nn.Sequential(nn.BatchNorm1d(256),nn.ReLU(),nn.Linear(256,2))\n",
    "        self.cnnaux = nn.Sequential(nn.BatchNorm1d(1000),nn.ReLU(),nn.Linear(1000,2)) \n",
    "        self.linear = nn.Linear(1256,2)\n",
    "    def forward(self,inputs):\n",
    "        x,meta_data = inputs\n",
    "        meta_features = self.meta_before(meta_data)\n",
    "        meta_out = self.metaaux(meta_features)\n",
    "        cnn_features = self.mainnet(x)\n",
    "        cnn_out = self.cnnaux(cnn_features)\n",
    "        features = torch.cat((cnn_features,meta_features),dim=1)\n",
    "        output = self.linear(features)\n",
    "        return output,meta_out,cnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "        self.net1 = nn.Sequential(nn.Linear(3,64),nn.BatchNorm1d(64),nn.ReLU())\n",
    "        self.net2 = nn.Sequential(nn.Linear(64,128),nn.BatchNorm1d(128),nn.ReLU())\n",
    "        self.net3 = nn.Linear(128,256)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        output = self.net3(self.net2(self.net1(inputs)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b3_ra-a5e2fbc7.pth\" to /root/.cache/torch/checkpoints/efficientnet_b3_ra-a5e2fbc7.pth\n"
     ]
    }
   ],
   "source": [
    "net = MetaNet()\n",
    "# model_pth = '../input/b6fold2/3/last-checkpoint.bin'\n",
    "# net.load_state_dict(torch.load(model_pth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/melanoma-merged-external-data-512x512-jpeg'\n",
    "TRAIN_ROOT_PATH = '../input/siim-isic-melanoma-classification/jpeg/train'\n",
    "TRAIN_ROOT_PATH0 = '../input/melanoma-merged-external-data-512x512-jpeg/512x512-dataset-melanoma/512x512-dataset-melanoma'\n",
    "\n",
    "train = pd.read_csv(f'{DATA_PATH}/marking.csv')\n",
    "test = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')\n",
    "train['sex'] = train['sex'].fillna('na')\n",
    "train['age_approx'] = train['age_approx'].fillna(0)\n",
    "train['anatom_site_general_challenge'] = train['anatom_site_general_challenge'].fillna('na')\n",
    "test['sex'] = test['sex'].fillna('na')\n",
    "test['age_approx'] = test['age_approx'].fillna(0)\n",
    "test['anatom_site_general_challenge'] = test['anatom_site_general_challenge'].fillna('na')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "train.sex = le.fit_transform(train.sex)\n",
    "train.anatom_site_general_challenge = le.fit_transform(train.anatom_site_general_challenge)\n",
    "train['age_approx'] = le.fit_transform(train['age_approx'])\n",
    "test.sex = le.fit_transform(test.sex)\n",
    "test.anatom_site_general_challenge = le.fit_transform(test.anatom_site_general_challenge)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(train[['sex','age_approx','anatom_site_general_challenge']])\n",
    "train.sex,train.age_approx,train.anatom_site_general_challenge = x[:,0],x[:,1],x[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def onehot(size, target):\n",
    "    vec = torch.zeros(size, dtype=torch.float32)\n",
    "    vec[target] = 1.\n",
    "    return vec\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "\n",
    "    def __init__(self, df, image_ids, labels, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_id = self.image_ids[idx]\n",
    "#         print(image_id)\n",
    "        try:\n",
    "            image = cv2.imread(f'{TRAIN_ROOT_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "        except:\n",
    "            image = cv2.imread(f'{TRAIN_ROOT_PATH0}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "        record = self.df[self.df.image_id == image_id]\n",
    "        meta_data = np.squeeze(record[['sex','age_approx','anatom_site_general_challenge']].values)\n",
    "        label = self.labels[idx]\n",
    "        meta_data = torch.tensor(meta_data,dtype=torch.float32)\n",
    "        if self.transforms:\n",
    "            sample = {'image': image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "        target = onehot(2, label)\n",
    "        return (image,meta_data), target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def get_labels(self):\n",
    "        return list(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_folds = pd.read_csv(f'{DATA_PATH}/folds.csv', index_col='image_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fitter:\n",
    "    \n",
    "    def __init__(self, model, device, config, folder):\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.base_dir = f'./{folder}'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.makedirs(self.base_dir)\n",
    "\n",
    "        self.log_path = f'{self.base_dir}/log.txt'\n",
    "        self.best_score = 0\n",
    "        self.best_loss = 10**5\n",
    "        self.best_ap = 0\n",
    "        self.best_swa = 0\n",
    "        \n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        \n",
    "        self.base_optimizer = optim.AdamW(self.model.parameters(), lr=config.lr)\n",
    "        self.optimizer = SWA(self.base_optimizer)\n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "        self.main_criterion = LabelSmoothing().to(self.device)\n",
    "        self.cnn_criterion = FocalDiceLoss(logits=True).to(self.device)\n",
    "        self.meta_criterion = FocalLoss(logits=True).to(self.device)\n",
    "        self.log(f'Fitter prepared. Device is {self.device}')\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "\n",
    "            t = time.time()\n",
    "\n",
    "                    \n",
    "            summary_main_loss,summary_meta_loss,summary_cnn_loss, roc_auc_scores, ap_scores = self.train_one_epoch(train_loader)\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, main_loss: {summary_main_loss.avg:.5f},cnn_loss: {summary_cnn_loss.avg:.5f},meta_loss: {summary_meta_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "            \n",
    "                \n",
    "            t = time.time()\n",
    "            \n",
    "            if self.epoch >15 or roc_auc_scores.avg > 0.89:\n",
    "                self.optimizer.update_swa()\n",
    "                \n",
    "            summary_main_loss,summary_meta_loss,summary_cnn_loss, roc_auc_scores, ap_scores = self.validation(validation_loader) \n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, main_loss: {summary_main_loss.avg:.5f},cnn_loss: {summary_cnn_loss.avg:.5f},meta_loss: {summary_meta_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "            if summary_main_loss.avg < self.best_loss:\n",
    "                self.best_loss = summary_main_loss.avg\n",
    "                self.save_model(f'{self.base_dir}/best-loss-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-loss-checkpoint-*epoch.bin'))[:-1]:\n",
    "                    os.remove(path)\n",
    "                    \n",
    "            if roc_auc_scores.avg > self.best_score:\n",
    "                self.best_score = roc_auc_scores.avg\n",
    "                self.save_model(f'{self.base_dir}/best-score-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-score-checkpoint-*epoch.bin'))[:-4]:\n",
    "                    os.remove(path)\n",
    "                    \n",
    "            if ap_scores.avg > self.best_ap:\n",
    "                self.best_ap = ap_scores.avg\n",
    "                self.save_model(f'{self.base_dir}/best-ap-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-ap-checkpoint-*epoch.bin'))[:-1]:\n",
    "                    os.remove(path)\n",
    "            \n",
    "            if self.config.validation_scheduler:\n",
    "                self.scheduler.step(metrics=summary_main_loss.avg)\n",
    "            self.epoch += 1\n",
    "            if self.epoch == self.config.n_epochs:\n",
    "                self.save_model(f'{self.base_dir}/last-checkpoint.bin')\n",
    "                self.optimizer.swap_swa_sgd()\n",
    "                print(\"SWA WEIGHTS\")\n",
    "                summary_main_loss,summary_meta_loss,summary_cnn_loss, roc_auc_scores, ap_scores = self.validation(validation_loader)\n",
    "                print(roc_auc_scores)\n",
    "                self.save_model(f'{self.base_dir}/last-checkpoint-swa.bin')\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        \n",
    "        summary_main_loss = AverageMeter()\n",
    "        summary_meta_loss = AverageMeter()\n",
    "        summary_cnn_loss = AverageMeter()\n",
    "        \n",
    "        roc_auc_scores = RocAucMeter()\n",
    "        ap_scores = APScoreMeter()\n",
    "        t = time.time()\n",
    "        for step, (data, targets) in enumerate(val_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Val Step {step}/{len(val_loader)}, ' + \\\n",
    "                        f'main_loss: {summary_main_loss.avg:.5f},cnn_loss: {summary_cnn_loss.avg:.5f},meta_loss: {summary_meta_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f} ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                targets = targets.to(self.device).float()\n",
    "                batch_size = data[0].shape[0]\n",
    "                data[0] = data[0].to(self.device).float()\n",
    "                data[1] = data[1].to(self.device).float()\n",
    "                outputs = self.model(data)\n",
    "                \n",
    "                main_loss = self.main_criterion(outputs[0], targets)\n",
    "                cnn_loss = self.cnn_criterion(outputs[2], targets)\n",
    "                meta_loss = self.meta_criterion(outputs[1],targets)\n",
    "                loss = main_loss + cnn_loss + meta_loss\n",
    "                \n",
    "                roc_auc_scores.update(targets, outputs[0])\n",
    "                ap_scores.update(targets, outputs[0])\n",
    "                summary_main_loss.update(main_loss.detach().item(), batch_size)\n",
    "                summary_meta_loss.update(meta_loss.detach().item(), batch_size)\n",
    "                summary_cnn_loss.update(cnn_loss.detach().item(), batch_size)\n",
    "\n",
    "        return summary_main_loss,summary_meta_loss,summary_cnn_loss, roc_auc_scores, ap_scores\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        summary_main_loss = AverageMeter()\n",
    "        summary_meta_loss = AverageMeter()\n",
    "        summary_cnn_loss = AverageMeter()\n",
    "        roc_auc_scores = RocAucMeter()\n",
    "        ap_scores = APScoreMeter()\n",
    "        t = time.time()\n",
    "        for step, (data, targets) in enumerate(train_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Train Step {step}/{len(train_loader)}, ' + \\\n",
    "                        f'main_loss: {summary_main_loss.avg:.5f},cnn_loss: {summary_cnn_loss.avg:.5f},meta_loss: {summary_meta_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f} ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            targets = targets.to(self.device).float()\n",
    "            data[0] = data[0].to(self.device).float()\n",
    "            data[1] = data[1].to(self.device).float()\n",
    "            batch_size = data[0].shape[0]\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(data)\n",
    "            \n",
    "            main_loss = self.main_criterion(outputs[0], targets)\n",
    "            cnn_loss = self.cnn_criterion(outputs[2], targets)\n",
    "            meta_loss = self.meta_criterion(outputs[1],targets)\n",
    "            loss = main_loss + cnn_loss + meta_loss\n",
    "            loss.backward()\n",
    "            \n",
    "            roc_auc_scores.update(targets, outputs[0])\n",
    "            ap_scores.update(targets, outputs[0])\n",
    "            \n",
    "            summary_main_loss.update(main_loss.detach().item(), batch_size)\n",
    "            summary_meta_loss.update(meta_loss.detach().item(), batch_size)\n",
    "            summary_cnn_loss.update(cnn_loss.detach().item(), batch_size)\n",
    "\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "        return summary_main_loss,summary_meta_loss,summary_cnn_loss, roc_auc_scores, ap_scores\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save(self.model.state_dict(),path)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_score': self.best_score,\n",
    "            'best_ap': self.best_ap,\n",
    "            'best_loss': self.best_loss,\n",
    "            'epoch': self.epoch,\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.best_score = checkpoint['best_score']\n",
    "        self.best_ap = checkpoint['best_ap']\n",
    "        self.best_loss = checkpoint['best_loss']\n",
    "        self.epoch = checkpoint['epoch']\n",
    "        \n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 2\n",
    "    batch_size = 8\n",
    "    n_epochs = 20\n",
    "    lr = 0.00005\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = False  # do scheduler.step after optimizer.step\n",
    "    validation_scheduler = True  # do scheduler.step after validation stage loss\n",
    "\n",
    "    \n",
    "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    scheduler_params = dict(\n",
    "        mode='min',\n",
    "        factor=0.8,\n",
    "        patience=1,\n",
    "        verbose=False, \n",
    "        threshold=0.0001,\n",
    "        threshold_mode='abs',\n",
    "        cooldown=0, \n",
    "        min_lr=1e-8,\n",
    "        eps=1e-08\n",
    "    )\n",
    "    # --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all states for \"honest\" training of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "fitter = Fitter(model=net, device=torch.device('cuda:0'), config=TrainGlobalConfig, folder='base_state')\n",
    "BASE_STATE_PATH = f'{fitter.base_dir}/base_state.bin'\n",
    "fitter.save(BASE_STATE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(fold_number):\n",
    "\n",
    "    train_dataset = DatasetRetriever(df = train,\n",
    "        image_ids=df_folds[df_folds['fold'] != fold_number].index.values,\n",
    "        labels=df_folds[df_folds['fold'] != fold_number].target.values,\n",
    "        transforms=get_train_transforms(),\n",
    "    )\n",
    "\n",
    "    df_val = df_folds[(df_folds['fold'] == fold_number) & (df_folds['source'] == 'ISIC20')]\n",
    "\n",
    "    validation_dataset = DatasetRetriever(df= train,\n",
    "        image_ids=df_val.index.values,\n",
    "        labels=df_val.target.values,\n",
    "        transforms=get_valid_transforms(),\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        validation_dataset, \n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(validation_dataset),\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net.cuda(), device=torch.device('cuda:0'), config=TrainGlobalConfig, folder=f'{fold_number}')\n",
    "    fitter.load(BASE_STATE_PATH)\n",
    "    print(\"strat\")\n",
    "    fitter.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "train_fold(fold_number=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference(Without TTA)\n",
    "#### For TTA just replace get_valid_transforms() with get_train_transforms() and predict the output multiple times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pth = '../input/b6fold2/4/best-ap-checkpoint-010epoch.bin'  ##path to be changed multiple times\n",
    "net.load_state_dict(torch.load(model_pth))\n",
    "net = net.cuda()\n",
    "\n",
    "test_dataset = DatasetRetriever(df= test,\n",
    "        image_ids=test.image_name.values,\n",
    "        labels=np.zeros(len(test), dtype = int),\n",
    "        transforms=get_valid_transforms(),\n",
    "    )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        pin_memory=False,\n",
    "        num_workers=8,\n",
    "        shuffle = False\n",
    "    )\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "from tqdm import tqdm\n",
    "result = []\n",
    "with torch.no_grad():\n",
    "    for i, (data, targets) in tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "        torch.cuda.empty_cache()\n",
    "        data[0] = data[0].cuda().float()\n",
    "        data[1] = data[1].cuda()\n",
    "        output,meta_out,cnn_out = net(data)\n",
    "        out = 1/3*(softmax(output, dim = 1) + softmax(meta_out, dim = 1)  + softmax(cnn_out, dim = 1) )\n",
    "        result.extend(out[:, 1].detach().cpu().tolist())\n",
    "        \n",
    "submission = pd.DataFrame({'image_name' : test.image_name, 'target' : result})\n",
    "submission.to_csv('tfb6_fold4_ap.csv', header = submission.columns, index =  False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
